{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "534cbd72",
   "metadata": {},
   "source": [
    "# Export TFLITE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4edb9c57",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.python.distribute.distribution_strategy_context'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtf\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01multralytics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m YOLO\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01monnx2tf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m convert\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lin40269\\Desktop\\Linh\\01_Python\\realsense\\.venv\\Lib\\site-packages\\tensorflow\\__init__.py:45\u001b[39m\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf2 \u001b[38;5;28;01mas\u001b[39;00m _tf2\n\u001b[32m     43\u001b[39m _tf2.enable()\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_api\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __internal__\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_api\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __operators__\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_api\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m audio\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lin40269\\Desktop\\Linh\\01_Python\\realsense\\.venv\\Lib\\site-packages\\tensorflow\\_api\\v2\\__internal__\\__init__.py:11\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m decorator\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dispatch\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m distribute\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m eager_context\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m feature_column\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lin40269\\Desktop\\Linh\\01_Python\\realsense\\.venv\\Lib\\site-packages\\tensorflow\\_api\\v2\\__internal__\\distribute\\__init__.py:11\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m interim\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m multi_process_runner\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistribute\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistribution_strategy_context\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m variable_sync_on_read_context\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistribute\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmerge_call_interim\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m strategy_supports_no_merge_call\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistribute\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msharded_variable\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ShardedVariable\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'tensorflow.python.distribute.distribution_strategy_context'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from ultralytics import YOLO\n",
    "from onnx2tf import convert\n",
    "\n",
    "# Paths\n",
    "PT_MODEL_PATH = 'models/focus1/Focus1_YOLO11s_x1024_14112024.pt'\n",
    "ONNX_MODEL_PATH = 'models/focus1/Focus1_YOLO11s_x1024_14112024.onnx'\n",
    "TF_SAVED_MODEL_DIR = 'models/focus1/tf_saved_model'\n",
    "TFLITE_MODEL_PATH = 'models/focus1/yolo11s_int8.tflite'\n",
    "\n",
    "# 1. Load YOLO PT model and export to ONNX\n",
    "model = YOLO(PT_MODEL_PATH)\n",
    "model.export(format='onnx', imgsz=1024)  # By default saves as <modelname>.onnx\n",
    "\n",
    "# Move or rename exported ONNX to desired path if necessary\n",
    "if not os.path.exists(ONNX_MODEL_PATH):\n",
    "    os.rename('Focus1_YOLO11s_x1024_14112024.onnx', ONNX_MODEL_PATH)\n",
    "\n",
    "# 2. Convert ONNX to TensorFlow SavedModel using onnx2tf\n",
    "convert(\n",
    "    input_onnx_file_path=ONNX_MODEL_PATH,\n",
    "    output_folder_path=TF_SAVED_MODEL_DIR,\n",
    "    output_signaturedefs=True,          # Optional but recommended\n",
    "    copy_onnx_input_output_names_to_tflite=True\n",
    ")\n",
    "\n",
    "# 3. Define a representative dataset generator for INT8 quantization\n",
    "def representative_dataset():\n",
    "    # Replace with your actual calibration images or dataset loader\n",
    "    for _ in range(100):\n",
    "        # Example: yield random tensor of input shape (1, 1024, 1024, 3), float32 [0,1]\n",
    "        yield [tf.random.uniform(shape=(1, 1024, 1024, 3), dtype=tf.float32)]\n",
    "\n",
    "# 4. Convert TensorFlow SavedModel to INT8 quantized TFLite model\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(TF_SAVED_MODEL_DIR)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_dataset\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.uint8   # or tf.int8 depending on model requirement\n",
    "converter.inference_output_type = tf.uint8  # or tf.int8\n",
    "\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the quantized TFLite model\n",
    "with open(TFLITE_MODEL_PATH, 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(f'TFLite INT8 model saved to: {TFLITE_MODEL_PATH}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c1c645",
   "metadata": {},
   "source": [
    "# Export NCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "269e1e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.162  Python-3.11.9 torch-2.7.1+cu128 CPU (Intel Core(TM) Ultra 7 165H)\n",
      "YOLO11n summary (fused): 100 layers, 2,582,542 parameters, 0 gradients, 6.3 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'models\\focus1\\Focus1_YOLO11n_x1024_14112024.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 6, 8400) (5.3 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mTorchScript:\u001b[0m starting export with torch 2.7.1+cu128...\n",
      "\u001b[34m\u001b[1mTorchScript:\u001b[0m export success  1.9s, saved as 'models\\focus1\\Focus1_YOLO11n_x1024_14112024.torchscript' (10.4 MB)\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['ncnn'] not found, attempting AutoUpdate...\n",
      "Collecting ncnn\n",
      "  Downloading ncnn-1.0.20250503-cp311-cp311-win_amd64.whl.metadata (28 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\lin40269\\desktop\\linh\\01_python\\realsense\\.venv\\lib\\site-packages (from ncnn) (1.23.5)\n",
      "Requirement already satisfied: tqdm in c:\\users\\lin40269\\desktop\\linh\\01_python\\realsense\\.venv\\lib\\site-packages (from ncnn) (4.67.1)\n",
      "Requirement already satisfied: requests in c:\\users\\lin40269\\desktop\\linh\\01_python\\realsense\\.venv\\lib\\site-packages (from ncnn) (2.32.4)\n",
      "Collecting portalocker (from ncnn)\n",
      "  Downloading portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\lin40269\\desktop\\linh\\01_python\\realsense\\.venv\\lib\\site-packages (from ncnn) (4.11.0.86)\n",
      "Requirement already satisfied: pywin32>=226 in c:\\users\\lin40269\\desktop\\linh\\01_python\\realsense\\.venv\\lib\\site-packages (from portalocker->ncnn) (310)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\lin40269\\desktop\\linh\\01_python\\realsense\\.venv\\lib\\site-packages (from requests->ncnn) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lin40269\\desktop\\linh\\01_python\\realsense\\.venv\\lib\\site-packages (from requests->ncnn) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lin40269\\desktop\\linh\\01_python\\realsense\\.venv\\lib\\site-packages (from requests->ncnn) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lin40269\\desktop\\linh\\01_python\\realsense\\.venv\\lib\\site-packages (from requests->ncnn) (2025.6.15)\n",
      "Requirement already satisfied: colorama in c:\\users\\lin40269\\desktop\\linh\\01_python\\realsense\\.venv\\lib\\site-packages (from tqdm->ncnn) (0.4.6)\n",
      "Downloading ncnn-1.0.20250503-cp311-cp311-win_amd64.whl (3.8 MB)\n",
      "   ---------------------------------------- 3.8/3.8 MB 45.9 MB/s eta 0:00:00\n",
      "Downloading portalocker-3.2.0-py3-none-any.whl (22 kB)\n",
      "Installing collected packages: portalocker, ncnn\n",
      "   ---------------------------------------- 2/2 [ncnn]\n",
      "Successfully installed ncnn-1.0.20250503 portalocker-3.2.0\n",
      "\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success  2.2s\n",
      "WARNING \u001b[31m\u001b[1mrequirements:\u001b[0m \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[34m\u001b[1mNCNN:\u001b[0m starting export with NCNN 1.0.20250503...\n",
      "WARNING \u001b[34m\u001b[1mNCNN:\u001b[0m PNNX not found. Attempting to download binary file from https://github.com/pnnx/pnnx/.\n",
      "Note PNNX Binary file must be placed in current working directory or in C:\\Users\\lin40269\\Desktop\\Linh\\01_Python\\realsense\\.venv\\Lib\\site-packages\\ultralytics. See PNNX repo for full installation instructions.\n",
      "\u001b[34m\u001b[1mNCNN:\u001b[0m successfully found latest PNNX asset file pnnx-20250530-windows.zip\n",
      "Downloading https://github.com/pnnx/pnnx/releases/download/20250530/pnnx-20250530-windows.zip to 'pnnx-20250530-windows.zip'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16.6M/16.6M [00:00<00:00, 41.8MB/s]\n",
      "Unzipping pnnx-20250530-windows.zip to C:\\Users\\lin40269\\Desktop\\Linh\\01_Python\\realsense\\pnnx-20250530-windows...: 100%|██████████| 3/3 [00:00<00:00, 11.28file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mNCNN:\u001b[0m running 'C:\\Users\\lin40269\\Desktop\\Linh\\01_Python\\realsense\\.venv\\Lib\\site-packages\\ultralytics\\pnnx.exe models\\focus1\\Focus1_YOLO11n_x1024_14112024.torchscript ncnnparam=models\\focus1\\Focus1_YOLO11n_x1024_14112024_ncnn_model\\model.ncnn.param ncnnbin=models\\focus1\\Focus1_YOLO11n_x1024_14112024_ncnn_model\\model.ncnn.bin ncnnpy=models\\focus1\\Focus1_YOLO11n_x1024_14112024_ncnn_model\\model_ncnn.py pnnxparam=models\\focus1\\Focus1_YOLO11n_x1024_14112024_ncnn_model\\model.pnnx.param pnnxbin=models\\focus1\\Focus1_YOLO11n_x1024_14112024_ncnn_model\\model.pnnx.bin pnnxpy=models\\focus1\\Focus1_YOLO11n_x1024_14112024_ncnn_model\\model_pnnx.py pnnxonnx=models\\focus1\\Focus1_YOLO11n_x1024_14112024_ncnn_model\\model.pnnx.onnx fp16=1 device=cpu inputshape=\"[1, 3, 640, 640]\"'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mNCNN:\u001b[0m export success  12.3s, saved as 'models\\focus1\\Focus1_YOLO11n_x1024_14112024_ncnn_model' (5.1 MB)\n",
      "\n",
      "Export complete (14.7s)\n",
      "Results saved to \u001b[1mC:\\Users\\lin40269\\Desktop\\Linh\\01_Python\\realsense\\models\\focus1\u001b[0m\n",
      "Predict:         yolo predict task=detect model=models\\focus1\\Focus1_YOLO11n_x1024_14112024_ncnn_model imgsz=640 half \n",
      "Validate:        yolo val task=detect model=models\\focus1\\Focus1_YOLO11n_x1024_14112024_ncnn_model imgsz=640 data=/content/batrec-8/data.yaml half \n",
      "Visualize:       https://netron.app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'models\\\\focus1\\\\Focus1_YOLO11n_x1024_14112024_ncnn_model'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a YOLO11n PyTorch model\n",
    "model = YOLO(r\"models\\focus1\\Focus1_YOLO11n_x1024_14112024.pt\")\n",
    "\n",
    "# Export the model to NCNN format\n",
    "model.export(format=\"ncnn\", imgsz = 640, half = True)  # creates 'yolo11n_ncnn_model'\n",
    "\n",
    "# # Load the exported NCNN model\n",
    "# ncnn_model = YOLO(\"yolo11n_ncnn_model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
