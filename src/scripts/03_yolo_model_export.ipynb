{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "534cbd72",
   "metadata": {},
   "source": [
    "# Export TFLITE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4edb9c57",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.python.distribute.distribution_strategy_context'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtf\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01multralytics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m YOLO\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01monnx2tf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m convert\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lin40269\\Desktop\\Linh\\01_Python\\realsense\\.venv\\Lib\\site-packages\\tensorflow\\__init__.py:45\u001b[39m\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf2 \u001b[38;5;28;01mas\u001b[39;00m _tf2\n\u001b[32m     43\u001b[39m _tf2.enable()\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_api\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __internal__\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_api\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __operators__\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_api\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m audio\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lin40269\\Desktop\\Linh\\01_Python\\realsense\\.venv\\Lib\\site-packages\\tensorflow\\_api\\v2\\__internal__\\__init__.py:11\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m decorator\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dispatch\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m distribute\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m eager_context\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m feature_column\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lin40269\\Desktop\\Linh\\01_Python\\realsense\\.venv\\Lib\\site-packages\\tensorflow\\_api\\v2\\__internal__\\distribute\\__init__.py:11\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m interim\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m multi_process_runner\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistribute\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistribution_strategy_context\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m variable_sync_on_read_context\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistribute\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmerge_call_interim\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m strategy_supports_no_merge_call\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistribute\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msharded_variable\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ShardedVariable\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'tensorflow.python.distribute.distribution_strategy_context'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from ultralytics import YOLO\n",
    "from onnx2tf import convert\n",
    "\n",
    "# Paths\n",
    "PT_MODEL_PATH = 'models/focus1/Focus1_YOLO11s_x1024_14112024.pt'\n",
    "ONNX_MODEL_PATH = 'models/focus1/Focus1_YOLO11s_x1024_14112024.onnx'\n",
    "TF_SAVED_MODEL_DIR = 'models/focus1/tf_saved_model'\n",
    "TFLITE_MODEL_PATH = 'models/focus1/yolo11s_int8.tflite'\n",
    "\n",
    "# 1. Load YOLO PT model and export to ONNX\n",
    "model = YOLO(PT_MODEL_PATH)\n",
    "model.export(format='onnx', imgsz=1024)  # By default saves as <modelname>.onnx\n",
    "\n",
    "# Move or rename exported ONNX to desired path if necessary\n",
    "if not os.path.exists(ONNX_MODEL_PATH):\n",
    "    os.rename('Focus1_YOLO11s_x1024_14112024.onnx', ONNX_MODEL_PATH)\n",
    "\n",
    "# 2. Convert ONNX to TensorFlow SavedModel using onnx2tf\n",
    "convert(\n",
    "    input_onnx_file_path=ONNX_MODEL_PATH,\n",
    "    output_folder_path=TF_SAVED_MODEL_DIR,\n",
    "    output_signaturedefs=True,          # Optional but recommended\n",
    "    copy_onnx_input_output_names_to_tflite=True\n",
    ")\n",
    "\n",
    "# 3. Define a representative dataset generator for INT8 quantization\n",
    "def representative_dataset():\n",
    "    # Replace with your actual calibration images or dataset loader\n",
    "    for _ in range(100):\n",
    "        # Example: yield random tensor of input shape (1, 1024, 1024, 3), float32 [0,1]\n",
    "        yield [tf.random.uniform(shape=(1, 1024, 1024, 3), dtype=tf.float32)]\n",
    "\n",
    "# 4. Convert TensorFlow SavedModel to INT8 quantized TFLite model\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(TF_SAVED_MODEL_DIR)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_dataset\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.uint8   # or tf.int8 depending on model requirement\n",
    "converter.inference_output_type = tf.uint8  # or tf.int8\n",
    "\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the quantized TFLite model\n",
    "with open(TFLITE_MODEL_PATH, 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(f'TFLite INT8 model saved to: {TFLITE_MODEL_PATH}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c1c645",
   "metadata": {},
   "source": [
    "# Export NCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "269e1e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.177  Python-3.11.13 torch-2.8.0+cu128 CPU (AMD Ryzen 7 4800H with Radeon Graphics)\n",
      "YOLO11x summary (fused): 190 layers, 56,829,334 parameters, 0 gradients, 194.4 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'C:\\Users\\ADMIN\\Desktop\\Work\\Master\\ReUsePython\\weights\\..\\models\\original\\Focus1_YOLO11x_x1024_14112024.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 6, 8400) (109.2 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mTorchScript:\u001b[0m starting export with torch 2.8.0+cu128...\n",
      "\u001b[34m\u001b[1mTorchScript:\u001b[0m export success  10.3s, saved as 'C:\\Users\\ADMIN\\Desktop\\Work\\Master\\ReUsePython\\weights\\..\\models\\original\\Focus1_YOLO11x_x1024_14112024.torchscript' (217.9 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mNCNN:\u001b[0m starting export with NCNN 1.0.20250503...\n",
      "\u001b[34m\u001b[1mNCNN:\u001b[0m running 'C:\\Users\\ADMIN\\Desktop\\Work\\Master\\ReUsePython\\.venv\\Lib\\site-packages\\ultralytics\\pnnx.exe C:\\Users\\ADMIN\\Desktop\\Work\\Master\\ReUsePython\\weights\\..\\models\\original\\Focus1_YOLO11x_x1024_14112024.torchscript ncnnparam=C:\\Users\\ADMIN\\Desktop\\Work\\Master\\ReUsePython\\weights\\..\\models\\original\\Focus1_YOLO11x_x1024_14112024_ncnn_model\\model.ncnn.param ncnnbin=C:\\Users\\ADMIN\\Desktop\\Work\\Master\\ReUsePython\\weights\\..\\models\\original\\Focus1_YOLO11x_x1024_14112024_ncnn_model\\model.ncnn.bin ncnnpy=C:\\Users\\ADMIN\\Desktop\\Work\\Master\\ReUsePython\\weights\\..\\models\\original\\Focus1_YOLO11x_x1024_14112024_ncnn_model\\model_ncnn.py pnnxparam=C:\\Users\\ADMIN\\Desktop\\Work\\Master\\ReUsePython\\weights\\..\\models\\original\\Focus1_YOLO11x_x1024_14112024_ncnn_model\\model.pnnx.param pnnxbin=C:\\Users\\ADMIN\\Desktop\\Work\\Master\\ReUsePython\\weights\\..\\models\\original\\Focus1_YOLO11x_x1024_14112024_ncnn_model\\model.pnnx.bin pnnxpy=C:\\Users\\ADMIN\\Desktop\\Work\\Master\\ReUsePython\\weights\\..\\models\\original\\Focus1_YOLO11x_x1024_14112024_ncnn_model\\model_pnnx.py pnnxonnx=C:\\Users\\ADMIN\\Desktop\\Work\\Master\\ReUsePython\\weights\\..\\models\\original\\Focus1_YOLO11x_x1024_14112024_ncnn_model\\model.pnnx.onnx fp16=1 device=cpu inputshape=\"[1, 3, 640, 640]\"'\n",
      "\u001b[34m\u001b[1mNCNN:\u001b[0m export success  19.0s, saved as 'C:\\Users\\ADMIN\\Desktop\\Work\\Master\\ReUsePython\\weights\\..\\models\\original\\Focus1_YOLO11x_x1024_14112024_ncnn_model' (108.7 MB)\n",
      "\n",
      "Export complete (32.7s)\n",
      "Results saved to \u001b[1mC:\\Users\\ADMIN\\Desktop\\Work\\Master\\ReUsePython\\models\\original\u001b[0m\n",
      "Predict:         yolo predict task=detect model=C:\\Users\\ADMIN\\Desktop\\Work\\Master\\ReUsePython\\weights\\..\\models\\original\\Focus1_YOLO11x_x1024_14112024_ncnn_model imgsz=640 half \n",
      "Validate:        yolo val task=detect model=C:\\Users\\ADMIN\\Desktop\\Work\\Master\\ReUsePython\\weights\\..\\models\\original\\Focus1_YOLO11x_x1024_14112024_ncnn_model imgsz=640 data=/content/batrec-8/data.yaml half \n",
      "Visualize:       https://netron.app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\ADMIN\\\\Desktop\\\\Work\\\\Master\\\\ReUsePython\\\\weights\\\\..\\\\models\\\\original\\\\Focus1_YOLO11x_x1024_14112024_ncnn_model'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a YOLO11 PyTorch model\n",
    "model = YOLO(r\"..\\models\\original\\Focus1_YOLO11x_x1024_14112024.pt\")\n",
    "\n",
    "# Export the model to NCNN format\n",
    "model.export(format=\"ncnn\", imgsz = 640, half = True)  # creates 'yolo11n_ncnn_model'\n",
    "\n",
    "# # Load the exported NCNN model\n",
    "# ncnn_model = YOLO(\"yolo11n_ncnn_model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ReUsePython",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
